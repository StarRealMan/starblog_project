---
title: 老婆不够D？那就自己造！
top: false
date: 2021-7-10 20:10:37
categories: 开发
tags:
pic:
toc: true
---

神经网络真是个神奇的东西，它既能识别图像中的物品属于哪一种类，又能定位视频中目标，甚至能够听懂人类的语言，简直就是无所不能！可你是否想过，神经网络甚至能够进行创作，能够生成世界上根本不存在的东西呢？

### 基本原理

随着最近AI换脸的火爆，一个特别的神经网络再次走进了人们的视野，他就是生成对抗神经网络（GAN）。就像上文描述的，它能够生成世界上根本不存在的物体，也就是进行创作！

你一定很想知道，他是怎样进行创作的呢？他与其他种类的神经网络有什么本质区别呢？他的基本原理是如何呢？

GAN通常由两个基本结构组成，一个是Discriminator，也叫判别器，另一个是Generator，也叫生成器。生成器的作用很好理解，就是将一个高维的隐向量转换为一张图片，当然这张图片一定是越能够“以假乱真”，越好。按照传统的神经网络设计方法，我们只需要训练这个网络，使得网络拟合一个从高维隐向量空间到目标图片的任务空间的函数即可，这就涉及到一个问题，网络怎样才能学会我们想要的图片是怎样的呢？我们怎样监督这个网络呢？

于是，聪明的Ian J. Goodfellow发明了这样一种训练方式：设计一种判别器，能够判断图片是否由生成器生成，再对生成器生成的图片进行评价，进而对生成器进行了监督。想法很好，可是这种判别器该怎样得到呢？别着急，在论文中，Goodfellow将判别器和生成器进行了结合使得二者同时训练，判别器使用外部数据作为正样本，使用生成器生成图片作为负样本进行监督，而生成器则通过判别器进行监督，二者相互学习，互相对抗，这也是网络被称为生成**对抗**神经网络的原因。

网络的Loss设计成如下形式：

![real samples](/images/2021/老婆不够D？那就自己造！/loss.png)

网络的基本步骤如下：
1. 使用真实数据作为正样本训练D网络
2. 使用G网络生成数据作为负样本训练D网络（此时使用detach，不影响G网络参数）
3. 不进行detach，将G网络生成数据送入D网络进行训练（此时只更新G网络参数，不影响D网络参数）

经过上述步骤的反复迭代，最终D网络想要趋向于能够很精准的判断图片是来自真实分布还是来自于G网络的生成，同时G网络会努力地生成不被D网络发现为假的图片，二者就像矛和盾一样互相对抗，最终二者都能够学到真实样本深层次的分布特征。

在进行inference时，只需使用G网络即可产生想要的全新图片（同时D网络也可以用来进行真伪辨别等工作）

### 进行实验

作为一个老二次元，GAN这东西能生成不存在物体的特性，不拿来用用生成二次元老婆实在是说不过去啊，于是我借鉴DCGAN这篇经典论文，搭建了一个最简单的GAN网络，能够学习老婆们的特征，进而生成新的老婆，真是太香了！

Github：[Waifu_Generator](https://github.com/StarRealMan/Waifu_Generator)

原始DCGAN改进之前GAN使用的全连接层，D、G网络均使用卷积层进行特征提取，使用很浅的5层网络，最终能够生成64X64分辨率的图片。

我使用的数据集来源于Waifu2x，同样也是GAN领域著名的超分辨率方法得到的256X256分辨率的二次元老婆数据集，共有20000左右的样本，如下图所示：

![real samples](/images/2021/老婆不够D？那就自己造！/real_samples.png)

这是使用原生DCGAN训练50轮生成的图片：

![dcgan result](/images/2021/老婆不够D？那就自己造！/fake_samples_epoch_049.png)

我们拿着这么好的数据，难道会只满足于如此低分辨率图片的生成吗？于是我们对网络进行了进一步的改进，增加了深度到7层，增加分辨率到256X256，同时加大了feature channel，可惜效果不佳，网络时常陷入不均衡的状态（即D网络很强大，G网络不能与之抗衡），于是只好妥协，生成128X128的图片，进行了32轮训练，以下是效果：

![ours result](/images/2021/老婆不够D？那就自己造！/fake_samples_epoch_031.png)

当然我们的研究还未停止！分析我失败的原因，主要在于：数据量不够、高分辨率图片生成需要更深的网络、训练轮数不够、学习率等超参调节等多种原因。进一步提升分辨率的方法，可能在于加深网络层数，使用残差网络、数据增强等方法。

### 进一步研究

真阿宅怎能满足于浅尝辄止？还有更广阔的世界等着我们去探索！

首先比较好的方向在于：生成的老婆完全取决于这个隐向量，而这个隐向量的具体维度没有意义（是多语义严重耦合、且与训练过程相关的），我们如何控制生成老婆的各种属性（如发色、瞳色、眼镜等等）以满足我们的XP系统呢？Conditional GAN应运而生。

![只想要白毛？](/images/2021/老婆不够D？那就自己造！/white.png)

cGAN的目标在于，在G网络的输入中加入一个属性向量c，能够生成对应的图片，当然也需要在训练中对不同的真实样本进行标注，使D网络获取属性向量c的意义，并进行判别，从而使G网络也能学到这层意义。这个向量可以是multi hot的，也可以是数值的，网络甚至可以学到中间值的意义，见下图：

![渐变发色与嘴巴张开程度](/images/2021/老婆不够D？那就自己造！/fade.png)

同时StyleGAN提出了风格（Style）这一理论，认为不同分布的两组数据也具有共同的特征，也就是风格，可以用隐向量来表示，并提出了新的Project方法，能够将一种分布的风格进行投影，到另一种分布，这就是所谓风格迁移。

![风格迁移](/images/2021/老婆不够D？那就自己造！/style.png)

使用风格迁移，我们就能完成AI换脸、AI脱衣等任务了，是不是很神奇！

由于GAN的异军突起，很多人认为画师等行业中将没落，但是我始终认为，GAN虽然能创造出从未存在过的事物，但也是网络对作品进行学习而得来的，不能叫做真正意义上的创作，比不上人类的创作灵魂。画师、作曲家等创作者仍有着无可替代的地位，创作者万岁！